{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='../../datasets/', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = MNIST(root='../../datasets/', train=False)\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<PIL.Image.Image image mode=L size=28x28 at 0x7FD84AFE1BE0>, 5),\n",
       " (<PIL.Image.Image image mode=L size=28x28 at 0x7FD84AFE1C18>, 7))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0], test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd8308e5a58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[0]\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(n, val_pct, targets=None, stratify=False):\n",
    "    if targets and stratify:\n",
    "        return train_test_split(\n",
    "            np.arange(n),\n",
    "            test_size=val_pct,\n",
    "            shuffle=True,\n",
    "            stratify=targets)\n",
    "    elif not targets:\n",
    "        n_val = int(val_pct*n)\n",
    "        idxs = np.random.permutation(n)\n",
    "        return idxs[n_val:], idxs[:n_val]\n",
    "    else:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = MNIST(root=\"../../datasets/\", train=True, \n",
    "           transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_tensor, label = df[0]\n",
    "img_tensor.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unstratified data\n",
    "# ti, vi = split_indices(len(df), .2)\n",
    "# len(ti), len(vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified training data\n",
    "# ti, vi = split_indices(len(df), .2, targets=[i[1] for i in df], stratify=True)\n",
    "# len(ti), len(vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# lets start using tdf and vdf instead of df, tdf \n",
    "ti, vi = split_indices(len(df), .2, targets=[i[1] for i in df], stratify=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 128\n",
    "train_sampler = SubsetRandomSampler(ti)\n",
    "val_sampler = SubsetRandomSampler(vi)\n",
    "\n",
    "\n",
    "tdl = DataLoader(df, BATCH_SIZE, sampler=train_sampler)\n",
    "vdl = DataLoader(df, BATCH_SIZE, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SIZE = 28 * 28\n",
    "NUM_CLASSES = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(INPUT_SIZE, NUM_CLASSES)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x7fd84afd9f10>\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 10]),\n",
       " tensor([ 0.1680,  0.3099,  0.2513, -0.2111, -0.0542,  0.2912,  0.2971, -0.0871,\n",
       "          0.0902,  0.1304]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for images, labels in tdl:\n",
    "    outputs = model(images)\n",
    "    break\n",
    "\n",
    "outputs.shape, outputs[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, true):\n",
    "    _, ops = torch.max(pred, dim=1)\n",
    "    return torch.sum(ops == true).item() / len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = .001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(m, l_func, xb, yb, opt=None, metric=None):\n",
    "    preds = m(xb)\n",
    "    loss = l_func(preds, yb)\n",
    "    \n",
    "    \n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    \n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        metric_result = metric(preds, yb)\n",
    "        \n",
    "    return loss.item(), len(xb), metric_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(m, l_func, valid_dl, metric=None):\n",
    "    with torch.no_grad():\n",
    "        results = [loss_batch(m, l_func, xb, yb, metric=metric) for xb, yb in valid_dl]\n",
    "        losses, nums, metrics = zip(*results)\n",
    "        total = np.sum(nums)\n",
    "        avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
    "        if metric is not None:\n",
    "            avg_metric = np.sum(np.multiply(metrics, nums)) / total\n",
    "    return avg_loss, total, avg_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 2.3074, Accuracy: 0.1144\n"
     ]
    }
   ],
   "source": [
    "val_loss, total, val_acc = evaluate(model, loss_func, vdl, metric=accuracy)\n",
    "print(\"loss : {:.4f}, Accuracy: {:.4f}\".format(val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, m, loss_f, opt, train_dl, valid_dl, metric=None):\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            loss, _, _ = loss_batch(m, loss_f, xb, yb, opt)\n",
    "        result = evaluate(m, loss_f, valid_dl, metric)\n",
    "        val_loss, total, val_metric = result\n",
    "        if metric is None:\n",
    "            print(\"epoch [{}/{}] loss : {:.4f} \".format(epoch + 1, epochs, val_loss))\n",
    "        else:\n",
    "            print(\"epoch [{}/{}] loss : {:.4f}, {}: {:.4f} \".format(epoch + 1, epochs, val_loss, metric.__name__, val_acc))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/5] loss : 1.9618, accuracy: 0.1144 \n",
      "epoch [2/5] loss : 1.6985, accuracy: 0.1144 \n",
      "epoch [3/5] loss : 1.5005, accuracy: 0.1144 \n",
      "epoch [4/5] loss : 1.3498, accuracy: 0.1144 \n",
      "epoch [5/5] loss : 1.2330, accuracy: 0.1144 \n"
     ]
    }
   ],
   "source": [
    "fit(5, model, F.cross_entropy, optimizer, tdl, vdl, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, m):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    \n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = MNIST(root='../../datasets/', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_df[1820]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "label, predict_image(img, model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
